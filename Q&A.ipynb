{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ffc354-ae48-43f2-8bde-4ac74289d2c1",
   "metadata": {},
   "source": [
    "## BERT DRIVEN QnA SYSTEM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6ac1a-8b12-48f6-a7ed-cf3457330b9f",
   "metadata": {},
   "source": [
    "In this notebook we will be creating QnA system with the help of BERT model on CoQA dataset. We will be doing pre-processing and then with the help of advanced NLP techniques such as token ID's we will extract answers from given context for the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97650f9c-3396-4f77-96e4-571db00754c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8569429c-77d8-4550-ac0d-75aeb468bddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fd1ed-8e8c-44b6-b355-94e7a24a319b",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6224c98-8cae-46b2-bd06-d371bc6ce567",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b97d1c-9d3e-4d29-9982-c587d2fb1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required columns in our dataframe\n",
    "cols = [\"text\",\"question\",\"answer\"]\n",
    "#list of lists to create our dataframe\n",
    "comp_list = []\n",
    "for index, row in df.iterrows():\n",
    "    for i in range(len(row[\"data\"][\"questions\"])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row[\"data\"][\"story\"])\n",
    "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "df1 = pd.DataFrame(comp_list, columns=cols) \n",
    "#saving the dataframe to csv file for further loading\n",
    "df1.to_csv(\"CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63625c5-ddfd-4256-bb7b-02e53acefc3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CoQA_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782dec53-e8da-407a-aecc-9a1a026d8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question and answers:  108647\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of question and answers: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4864a-98bd-466a-97cd-3d7807c1e006",
   "metadata": {},
   "source": [
    "### Importing Pre-Trained BERT Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca722b8d-6ed0-4755-8bc8-7ec78c00f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cb85f-0836-4dcb-a783-d5da7256693c",
   "metadata": {},
   "source": [
    "### Taking Random Question and Text and Creating Tokens and ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f3b487-48ed-4333-9d5c-442e8d44c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0c93d2-f3f3-4151-832b-b95be8c391c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 309 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2329610f-a127-4792-8f33-a6d2bde6220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "how        2,129\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "what       2,054\n",
      "can        2,064\n",
      "technology   2,974\n",
      "do         2,079\n",
      "to         2,000\n",
      "make       2,191\n",
      "the        1,996\n",
      "world      2,088\n",
      "better     2,488\n",
      "?          1,029\n",
      "three      2,093\n",
      "young      2,402\n",
      "people     2,111\n",
      "are        2,024\n",
      "starting   3,225\n",
      "new        2,047\n",
      "businesses   5,661\n",
      "to         2,000\n",
      "answer     3,437\n",
      "the        1,996\n",
      "question   3,160\n",
      ".          1,012\n",
      "eighteen   7,763\n",
      "-          1,011\n",
      "year       2,095\n",
      "-          1,011\n",
      "old        2,214\n",
      "mach      24,532\n",
      "was        2,001\n",
      "the        1,996\n",
      "youngest   6,587\n",
      "person     2,711\n",
      "in         1,999\n",
      "poland     3,735\n",
      "to         2,000\n",
      "receive    4,374\n",
      "money      2,769\n",
      "from       2,013\n",
      "others     2,500\n",
      "to         2,000\n",
      "develop    4,503\n",
      "his        2,010\n",
      "company    2,194\n",
      ".          1,012\n",
      "he         2,002\n",
      "started    2,318\n",
      "five       2,274\n",
      ",          1,010\n",
      "a          1,037\n",
      "mobile     4,684\n",
      "messaging  24,732\n",
      "app       10,439\n",
      ",          1,010\n",
      "for        2,005\n",
      "deaf      12,419\n",
      "people     2,111\n",
      ".          1,012\n",
      "the        1,996\n",
      "app       10,439\n",
      "lets      11,082\n",
      "deaf      12,419\n",
      "people     2,111\n",
      "create     3,443\n",
      "their      2,037\n",
      "own        2,219\n",
      "hand       2,192\n",
      "signs      5,751\n",
      "to         2,000\n",
      "communicate  10,639\n",
      "with       2,007\n",
      "friends    2,814\n",
      ".          1,012\n",
      "the        1,996\n",
      "app       10,439\n",
      "now        2,085\n",
      "has        2,038\n",
      "more       2,062\n",
      "than       2,084\n",
      "10         2,184\n",
      ",          1,010\n",
      "000        2,199\n",
      "deaf      12,419\n",
      "users      5,198\n",
      ".          1,012\n",
      "and        1,998\n",
      "mach      24,532\n",
      "thinks     6,732\n",
      "there      2,045\n",
      "will       2,097\n",
      "be         2,022\n",
      "about      2,055\n",
      "150        5,018\n",
      ",          1,010\n",
      "000        2,199\n",
      "more       2,062\n",
      "deaf      12,419\n",
      "users      5,198\n",
      "next       2,279\n",
      "year       2,095\n",
      ".          1,012\n",
      "mach      24,532\n",
      "says       2,758\n",
      ",          1,010\n",
      "\"          1,000\n",
      "i          1,045\n",
      "love       2,293\n",
      "to         2,000\n",
      "create     3,443\n",
      ".          1,012\n",
      "i          1,045\n",
      "will       2,097\n",
      "stick      6,293\n",
      "to         2,000\n",
      "it         2,009\n",
      "to         2,000\n",
      "the        1,996\n",
      "end        2,203\n",
      "of         1,997\n",
      "my         2,026\n",
      "life       2,166\n",
      ".          1,012\n",
      "\"          1,000\n",
      "william    2,520\n",
      "zhou      14,367\n",
      "was        2,001\n",
      "born       2,141\n",
      "in         1,999\n",
      "beijing    7,211\n",
      "and        1,998\n",
      "grew       3,473\n",
      "up         2,039\n",
      "in         1,999\n",
      "canada     2,710\n",
      ".          1,012\n",
      "he         2,002\n",
      "strongly   6,118\n",
      "wanted     2,359\n",
      "to         2,000\n",
      "make       2,191\n",
      "a          1,037\n",
      "change     2,689\n",
      "in         1,999\n",
      "education   2,495\n",
      ".          1,012\n",
      "so         2,061\n",
      "he         2,002\n",
      "created    2,580\n",
      "chalk     16,833\n",
      ".          1,012\n",
      "it         2,009\n",
      "is         2,003\n",
      "a          1,037\n",
      "group      2,177\n",
      "of         1,997\n",
      "programs   3,454\n",
      "that       2,008\n",
      "supports   6,753\n",
      "individual   3,265\n",
      "teaching   4,252\n",
      "and        1,998\n",
      "learning   4,083\n",
      ".          1,012\n",
      "chalk     16,833\n",
      "is         2,003\n",
      "now        2,085\n",
      "used       2,109\n",
      "in         1,999\n",
      "20         2,322\n",
      ",          1,010\n",
      "000        2,199\n",
      "schools    2,816\n",
      "by         2,011\n",
      "more       2,062\n",
      "than       2,084\n",
      "100        2,531\n",
      ",          1,010\n",
      "000        2,199\n",
      "users      5,198\n",
      "worldwide   4,969\n",
      ".          1,012\n",
      "zhou      14,367\n",
      "says       2,758\n",
      "you        2,017\n",
      "have       2,031\n",
      "to         2,000\n",
      "find       2,424\n",
      "something   2,242\n",
      "you        2,017\n",
      "truly      5,621\n",
      "care       2,729\n",
      "about      2,055\n",
      ".          1,012\n",
      "or         2,030\n",
      "you        2,017\n",
      "may        2,089\n",
      "just       2,074\n",
      "end        2,203\n",
      "up         2,039\n",
      "giving     3,228\n",
      "it         2,009\n",
      "up         2,039\n",
      ".          1,012\n",
      "george     2,577\n",
      "was        2,001\n",
      "born       2,141\n",
      "in         1,999\n",
      "tanzania  11,959\n",
      ".          1,012\n",
      "he         2,002\n",
      "learned    4,342\n",
      "about      2,055\n",
      "renewable  13,918\n",
      "energy     2,943\n",
      "in         1,999\n",
      "europe     2,885\n",
      "and        1,998\n",
      "began      2,211\n",
      "thinking   3,241\n",
      "about      2,055\n",
      "using      2,478\n",
      "solar      5,943\n",
      "energy     2,943\n",
      "in         1,999\n",
      "africa     3,088\n",
      ".          1,012\n",
      "tanzania  11,959\n",
      "is         2,003\n",
      "a          1,037\n",
      "place      2,173\n",
      "with       2,007\n",
      "bright     4,408\n",
      "sunshine   9,609\n",
      ",          1,010\n",
      "but        2,021\n",
      "more       2,062\n",
      "than       2,084\n",
      "90         3,938\n",
      "percent    3,867\n",
      "of         1,997\n",
      "people     2,111\n",
      "have       2,031\n",
      "no         2,053\n",
      "electricity   6,451\n",
      "to         2,000\n",
      "use        2,224\n",
      ".          1,012\n",
      "after      2,044\n",
      "graduation   7,665\n",
      ",          1,010\n",
      "george     2,577\n",
      "returned   2,513\n",
      "to         2,000\n",
      "tanzania  11,959\n",
      "and        1,998\n",
      "started    2,318\n",
      "his        2,010\n",
      "own        2,219\n",
      "company    2,194\n",
      ",          1,010\n",
      "suns      19,352\n",
      "##wee     28,394\n",
      "##t        2,102\n",
      "solar      5,943\n",
      ".          1,012\n",
      "it         2,009\n",
      "has        2,038\n",
      "found      2,179\n",
      "early      2,220\n",
      "success    3,112\n",
      "in         1,999\n",
      "rural      3,541\n",
      "areas      2,752\n",
      ".          1,012\n",
      "george     2,577\n",
      "hopes      8,069\n",
      "to         2,000\n",
      "create     3,443\n",
      "jobs       5,841\n",
      "and        1,998\n",
      "help       2,393\n",
      "build      3,857\n",
      "his        2,010\n",
      "country    2,406\n",
      ".          1,012\n",
      "he         2,002\n",
      "understands  19,821\n",
      "the        1,996\n",
      "process    2,832\n",
      "will       2,097\n",
      "take       2,202\n",
      "time       2,051\n",
      ".          1,012\n",
      "\"          1,000\n",
      "but        2,021\n",
      "i          1,045\n",
      "think      2,228\n",
      "we         2,057\n",
      "are        2,024\n",
      "on         2,006\n",
      "the        1,996\n",
      "right      2,157\n",
      "way        2,126\n",
      ".          1,012\n",
      "\"          1,000\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:8}{:8,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af823389-8847-4e37-8239-21a5aac57da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEP token index:  3\n",
      "Number of tokens in segment A:  4\n",
      "Number of tokens in segment B:  305\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(\"SEP token index: \", sep_idx)\n",
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f490f-02b3-4536-9ff6-41e00263169f",
   "metadata": {},
   "source": [
    "### Extracting Answer from Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c770e0-b957-49a7-8e0d-17c0c24f14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
    "output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc9c1e8-80db-424c-922e-2e84f645b914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "How?\n",
      "\n",
      "Answer:\n",
      "[cls] how ? [sep] what can technology do to make the world better ? three young people are starting new businesses to answer the question . eighteen - year - old mach was the youngest person in poland to receive money from others to develop his company . he started five , a mobile messaging app , for deaf people . the app lets deaf people create their own hand signs to communicate with friends.\n"
     ]
    }
   ],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f62cd5-0072-42bd-9d06-a1fab970c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = tokens[answer_start]\n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer += tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dee855-b0fc-4023-acf3-69815ef6eca3",
   "metadata": {},
   "source": [
    "### Creating a Generalised Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a6d49c-8cb8-4f4d-b2ca-57270468d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "    #number of tokens in segment A (question)\n",
    "    num_seg_a = sep_idx+1\n",
    "    #number of tokens in segment B (text)\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s for segment embeddings\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767829c4-46b7-477f-aa82-470c298cafe0",
   "metadata": {},
   "source": [
    "### Comparing Our Answer and Original Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3dc8bd-3519-499f-b044-ab7006dbf7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "Hard rock cafe in new york ' s times square\n",
      "Original answer:\n",
      " Hard Rock Cafe\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. Profits from the auction at the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of only $120,000 in sales. The highly prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. Jackson's flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he debuted his revolutionary moonwalk. Fellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years ago, said he asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \"The legacy that [Jackson] left behind is bigger than life for me,\\\" Orange said. \\\"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\\\" Orange said he plans to give a portion of the proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.\"\"\"\n",
    "question = \"Where was the Auction held?\"\n",
    "question_answer(question, text)\n",
    "#original answer from the dataset\n",
    "print(\"Original answer:\\n\", data.loc[data[\"question\"] == question][\"answer\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1f3f0-87a9-4567-b438-a7790d6810f7",
   "metadata": {},
   "source": [
    "### Creating an Input Form for any Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b034f44d-c79d-4a0a-abb5-f2370e78613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your text: \n",
      " Narendra Damodardas Modi (Gujarati: [ˈnəɾendɾə dɑmodəɾˈdɑs ˈmodiː] ⓘ; born 17 September 1950)[a] is an Indian politician who has served as the 14th Prime Minister of India since 26 May 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the Member of Parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\n",
      "\n",
      "Please enter your question: \n",
      " Who is Narendra Modi ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "An indian politician who has served as the 14th prime minister of india\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to ask another question based on this text (Y/N)?  N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Please enter your text: \\n\")\n",
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    "while True:\n",
    "    question_answer(question, text)\n",
    "    \n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nBye!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
